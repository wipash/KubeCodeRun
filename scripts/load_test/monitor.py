"""Resource monitoring for load testing."""

import asyncio
import subprocess
import json
from typing import Any, Dict, List, Optional

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

from .models import DockerStats, SystemMetrics


class ResourceMonitor:
    """Monitor system resources during load testing."""

    def __init__(
        self,
        sample_interval: float = 1.0,
        enable_docker_stats: bool = True,
    ):
        self.sample_interval = sample_interval
        self.enable_docker_stats = enable_docker_stats
        self._running = False
        self._task: Optional[asyncio.Task] = None
        self._samples: List[SystemMetrics] = []
        self._docker_samples: List[DockerStats] = []
        self._initial_disk_io: Optional[tuple] = None
        self._initial_net_io: Optional[tuple] = None

    async def start(self) -> None:
        """Start monitoring in background."""
        if self._running:
            return

        self._running = True
        self._samples = []
        self._docker_samples = []

        # Capture initial I/O counters
        if PSUTIL_AVAILABLE:
            disk_io = psutil.disk_io_counters()
            if disk_io:
                self._initial_disk_io = (disk_io.read_bytes, disk_io.write_bytes)
            net_io = psutil.net_io_counters()
            if net_io:
                self._initial_net_io = (net_io.bytes_sent, net_io.bytes_recv)

        self._task = asyncio.create_task(self._sampling_loop())

    async def stop(self) -> SystemMetrics:
        """Stop monitoring and return aggregated metrics."""
        self._running = False
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
            self._task = None

        return self._aggregate_metrics()

    async def _sampling_loop(self) -> None:
        """Background loop to sample metrics."""
        while self._running:
            try:
                metrics = self._get_current_system_metrics()
                self._samples.append(metrics)

                if self.enable_docker_stats:
                    docker_stats = await self._get_docker_stats()
                    if docker_stats:
                        self._docker_samples.append(docker_stats)

                await asyncio.sleep(self.sample_interval)
            except asyncio.CancelledError:
                break
            except Exception:
                # Continue sampling even if one sample fails
                await asyncio.sleep(self.sample_interval)

    def _get_current_system_metrics(self) -> SystemMetrics:
        """Get current system metrics snapshot."""
        if not PSUTIL_AVAILABLE:
            return SystemMetrics()

        cpu_percent = psutil.cpu_percent(interval=None)
        memory = psutil.virtual_memory()

        # Calculate I/O deltas
        disk_read_mb = 0.0
        disk_write_mb = 0.0
        if self._initial_disk_io:
            disk_io = psutil.disk_io_counters()
            if disk_io:
                disk_read_mb = (disk_io.read_bytes - self._initial_disk_io[0]) / (1024 * 1024)
                disk_write_mb = (disk_io.write_bytes - self._initial_disk_io[1]) / (1024 * 1024)

        net_sent_mb = 0.0
        net_recv_mb = 0.0
        if self._initial_net_io:
            net_io = psutil.net_io_counters()
            if net_io:
                net_sent_mb = (net_io.bytes_sent - self._initial_net_io[0]) / (1024 * 1024)
                net_recv_mb = (net_io.bytes_recv - self._initial_net_io[1]) / (1024 * 1024)

        return SystemMetrics(
            cpu_percent_avg=cpu_percent,
            cpu_percent_max=cpu_percent,
            memory_percent_avg=memory.percent,
            memory_percent_max=memory.percent,
            memory_mb_used=memory.used / (1024 * 1024),
            memory_mb_available=memory.available / (1024 * 1024),
            disk_read_mb=disk_read_mb,
            disk_write_mb=disk_write_mb,
            network_sent_mb=net_sent_mb,
            network_recv_mb=net_recv_mb,
        )

    async def _get_docker_stats(self) -> Optional[DockerStats]:
        """Get Docker container statistics."""
        try:
            # Run docker stats --no-stream in subprocess
            proc = await asyncio.create_subprocess_exec(
                "docker", "stats", "--no-stream", "--format",
                '{"name":"{{.Name}}","cpu":"{{.CPUPerc}}","mem":"{{.MemUsage}}","mem_perc":"{{.MemPerc}}"}',
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )
            stdout, _ = await asyncio.wait_for(proc.communicate(), timeout=5.0)

            if proc.returncode != 0:
                return None

            containers = []
            total_cpu = 0.0
            total_memory_mb = 0.0

            for line in stdout.decode().strip().split("\n"):
                if not line:
                    continue
                try:
                    container = json.loads(line)
                    # Parse CPU percentage (e.g., "0.50%")
                    cpu_str = container.get("cpu", "0%").replace("%", "")
                    cpu = float(cpu_str) if cpu_str else 0.0
                    total_cpu += cpu

                    # Parse memory usage (e.g., "50MiB / 1GiB")
                    mem_str = container.get("mem", "0MiB / 0GiB").split("/")[0].strip()
                    mem_mb = self._parse_memory_string(mem_str)
                    total_memory_mb += mem_mb

                    containers.append({
                        "name": container.get("name", "unknown"),
                        "cpu_percent": cpu,
                        "memory_mb": mem_mb,
                    })
                except (json.JSONDecodeError, ValueError):
                    continue

            # Filter for kubecoderun containers only
            code_interpreter_containers = [
                c for c in containers
                if "kubecoderun" in c["name"].lower() or "executor" in c["name"].lower()
            ]

            return DockerStats(
                container_count=len(code_interpreter_containers),
                total_cpu_percent=sum(c["cpu_percent"] for c in code_interpreter_containers),
                total_memory_mb=sum(c["memory_mb"] for c in code_interpreter_containers),
                containers=code_interpreter_containers,
            )

        except (asyncio.TimeoutError, FileNotFoundError):
            return None
        except Exception:
            return None

    def _parse_memory_string(self, mem_str: str) -> float:
        """Parse memory string like '50MiB' or '1.5GiB' to MB."""
        mem_str = mem_str.strip().upper()
        try:
            if "GIB" in mem_str or "GB" in mem_str:
                return float(mem_str.replace("GIB", "").replace("GB", "")) * 1024
            elif "MIB" in mem_str or "MB" in mem_str:
                return float(mem_str.replace("MIB", "").replace("MB", ""))
            elif "KIB" in mem_str or "KB" in mem_str:
                return float(mem_str.replace("KIB", "").replace("KB", "")) / 1024
            else:
                return float(mem_str)
        except ValueError:
            return 0.0

    def _aggregate_metrics(self) -> SystemMetrics:
        """Aggregate all samples into summary metrics."""
        if not self._samples:
            return SystemMetrics()

        cpu_values = [s.cpu_percent_avg for s in self._samples]
        memory_values = [s.memory_percent_avg for s in self._samples]
        memory_used = [s.memory_mb_used for s in self._samples]

        # Get final I/O values from last sample
        last_sample = self._samples[-1]

        return SystemMetrics(
            cpu_percent_avg=sum(cpu_values) / len(cpu_values),
            cpu_percent_max=max(cpu_values),
            memory_percent_avg=sum(memory_values) / len(memory_values),
            memory_percent_max=max(memory_values),
            memory_mb_used=sum(memory_used) / len(memory_used),
            memory_mb_available=last_sample.memory_mb_available,
            disk_read_mb=last_sample.disk_read_mb,
            disk_write_mb=last_sample.disk_write_mb,
            network_sent_mb=last_sample.network_sent_mb,
            network_recv_mb=last_sample.network_recv_mb,
        )

    def get_docker_summary(self) -> Optional[DockerStats]:
        """Get aggregated Docker statistics."""
        if not self._docker_samples:
            return None

        # Calculate averages
        container_counts = [s.container_count for s in self._docker_samples]
        cpu_totals = [s.total_cpu_percent for s in self._docker_samples]
        memory_totals = [s.total_memory_mb for s in self._docker_samples]

        return DockerStats(
            container_count=max(container_counts) if container_counts else 0,
            total_cpu_percent=sum(cpu_totals) / len(cpu_totals) if cpu_totals else 0.0,
            total_memory_mb=max(memory_totals) if memory_totals else 0.0,
            containers=[],  # Don't include individual container details in summary
        )

    def get_current_metrics(self) -> SystemMetrics:
        """Get current system metrics snapshot (synchronous)."""
        return self._get_current_system_metrics()


async def get_docker_container_count() -> int:
    """Get count of running Docker containers."""
    try:
        proc = await asyncio.create_subprocess_exec(
            "docker", "ps", "-q",
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )
        stdout, _ = await asyncio.wait_for(proc.communicate(), timeout=5.0)

        if proc.returncode == 0:
            lines = stdout.decode().strip().split("\n")
            return len([l for l in lines if l])
        return 0
    except Exception:
        return 0
